import requests
import csv
import pandas as pd
import time
import os
import re

# Importar la clave de la API desde config.py
# Aseg√∫rate de que esta l√≠nea est√© correcta en tu entorno:
from config import SCRAPE_API_KEY

def get_tiktok_transcript(video_url: str, api_key: str, lang: str = 'es') -> str or None:
    """
    Realiza una llamada a la API de ScrapeCreators para obtener la transcripci√≥n de un video.
    """
    url = "https://api.scrapecreators.com/v1/tiktok/video/transcript"
    headers = {
        "x-api-key": api_key,
    }
    params = {
        "url": video_url,
        "language": lang
    }

    try:
        response = requests.get(url, headers=headers, params=params, timeout=20)
        response.raise_for_status()
        data = response.json()
        
        # Extraer el texto legible de la transcripci√≥n
        transcript_text = data.get('transcript', '')
        
        # Si la transcripci√≥n es una cadena vac√≠a o no v√°lida
        if not transcript_text or transcript_text.lower() in ('n/a', 'none', 'error'):
            return "TRANSCRIPCION_NO_DISPONIBLE" # Usar una marca de error espec√≠fica

        # Limpiar el texto: remover timestamps y otros metadatos
        clean_text = re.sub(r'(\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}\n)', '', transcript_text)
        clean_text = re.sub(r'WEBVTT\n\n', '', clean_text)
        clean_text = clean_text.replace('\n', ' ').strip()
        
        return clean_text
    
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error al conectar con la API para la URL {video_url}: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Ocurri√≥ un error inesperado al procesar la transcripci√≥n: {e}")
        return None

def main():
    """
    Funci√≥n principal para leer el CSV, obtener transcripciones y actualizar el archivo.
    Busca espec√≠ficamente 'N/A' en la columna 'transcript' para reanudar el trabajo.
    """
    input_filename = "base_de_datos_tiktok.csv"
    output_filename = "base_de_datos_tiktok.csv"
    
    # Tama√±o del lote para el guardado incremental
    BATCH_SIZE = 5 
    
    if not os.path.exists(input_filename):
        print(f"El archivo '{input_filename}' no se encontr√≥. Aseg√∫rate de haber ejecutado el script anterior.")
        return

    # Leer el archivo CSV
    try:
        # Forzar la lectura de 'transcript' como string para comparar con "N/A"
        df = pd.read_csv(input_filename, dtype={'transcript': str}) 
    except Exception as e:
        print(f"‚ùå Error al leer el archivo CSV: {e}")
        return
    
    # üìù IMPORTANTE: Asegurarse de que la columna exista y que los N/A sean 'N/A' si Pandas los convierte a NaN.
    if 'transcript' not in df.columns:
        df['transcript'] = 'N/A'
    # Rellenar cualquier valor NaN (valor nulo de Pandas) con "N/A" para el filtro
    df['transcript'] = df['transcript'].fillna('N/A') 

    print(f"‚úÖ Archivo cargado. Total de publicaciones: {len(df)}.")

    # Crear la m√°scara de filtro: buscar filas donde 'transcript' sea 'N/A'
    posts_to_process = df[df['transcript'] == 'N/A']
    
    if posts_to_process.empty:
        print("üéâ Todas las publicaciones ya tienen transcripci√≥n (o no tienen 'N/A'). Proceso finalizado.")
        return
    
    print(f"‚è≥ Se encontraron {len(posts_to_process)} publicaciones pendientes de transcripci√≥n.")

    # Recorrer solo las filas filtradas
    posts_processed = 0
    total_posts_processed_session = 0
    
    # Usamos .index para iterar sobre los √≠ndices originales del DataFrame
    for index in posts_to_process.index:
        row = df.loc[index]
        video_url = row.get('url')
        
        # Doble verificaci√≥n: si la URL falta, marcamos como error y continuamos
        if pd.isna(video_url) or video_url.strip() == '':
             df.loc[index, 'transcript'] = "URL_NO_VALIDA"
             continue

        print(f"Procesando fila (original): {index + 1}/{len(df)} | URL: {video_url[:50]}...")
        
        # Obtener la transcripci√≥n
        transcript = get_tiktok_transcript(video_url, SCRAPE_API_KEY, lang='es')
        
        if transcript:
            # Si hubo √©xito, guardamos la transcripci√≥n
            df.loc[index, 'transcript'] = transcript
            print(f"‚úîÔ∏è Transcripci√≥n obtenida (Tama√±o: {len(transcript)} caracteres).")
        else:
            # Si fall√≥ (Error de API, conexi√≥n, etc.), guardamos la marca de error para no reintentar de inmediato
            df.loc[index, 'transcript'] = "FALLO_API_REINTENTAR"
            print(f"‚ùå Fallo al obtener transcripci√≥n para la URL: {video_url}.")


        posts_processed += 1
        total_posts_processed_session += 1
        
        # üíæ Guardado Incremental üíæ
        if total_posts_processed_session % BATCH_SIZE == 0:
            df.to_csv(output_filename, index=False, quoting=csv.QUOTE_ALL)
            print(f"\nüíæ Avance guardado. Se actualizaron {BATCH_SIZE} registros. Total en sesi√≥n: {total_posts_processed_session}.")
            
        
        # Peque√±a pausa para no sobrecargar la API
        time.sleep(1)

    # Guardar los datos restantes al final del proceso
    if total_posts_processed_session % BATCH_SIZE != 0:
        df.to_csv(output_filename, index=False, quoting=csv.QUOTE_ALL)
        print(f"\nüíæ Proceso finalizado. Se actualizaron los √∫ltimos {total_posts_processed_session % BATCH_SIZE} registros. Total en sesi√≥n: {total_posts_processed_session}.")
    else:
        # Caso donde el √∫ltimo guardado coincidi√≥ con el BATCH_SIZE
        print(f"\nüéâ Proceso de extracci√≥n de transcripciones completado. Total de transcripciones intentadas: {total_posts_processed_session}.")

if __name__ == "__main__":
    main()
